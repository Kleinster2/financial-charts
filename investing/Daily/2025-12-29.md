# 2025-12-29

## Observations

- Restructured vault from 6 monolithic notes to 18 atomic notes
- [[TSMC]] emerged as the largest node in graph — confirms it's the analytical center of gravity
- Realized the difference between outgoing links and backlinks in graph sizing
- [[Samsung]] reportedly in talks with AMD for 2nm EPYC server chips — decision expected Jan 2026. Major potential customer win. [[Can Samsung ever catch TSMC]] [[Leading edge race]]
- TSMC's "N-2 rule" (Taiwan restricts leading-edge overseas) means Arizona can't do 2nm until Taiwan is 2 gens ahead. AMD/Google may turn to [[Samsung]] because [[TSMC]] 2nm capacity locked by Apple/NVIDIA
- Updated yield figures: [[Samsung]] 2nm at 40% (not 55-60%), [[TSMC]] 2nm at 65%, Intel 18A at 55%
- [[Samsung]] foundry market share down to 6.8% (was citing ~12%)
- [[SK Hynix]] planning first 2.5D packaging mass production line in Indiana (2028) — aims to compete with [[TSMC]] CoWoS monopoly. Turn-key play: HBM + packaging. "Korea's two semiconductor giants are basically trolling Taiwan" [[Advanced packaging]]
- U.S. revoked VEU status for [[Samsung]] and [[SK Hynix]] China fabs — now 1-year export approvals, can operate but can't expand. Caps China memory supply → higher DRAM prices → benefits Korean margins. [[Export controls]] [[Short TSMC long Korea]]
- [[AMD]]'s NodAI acquisition (late 2023) reshaping their software strategy. CEO Anush Elangovan driving software-hardware co-design. AMD now has "non-zero chance" of challenging [[CUDA moat]]. If AMD improves, bullish for whoever fabs their chips ([[Samsung]] 2nm deal). [[NVIDIA]]
- [[Samsung]] engineer leaked DRAM process secrets to China's CXMT via handwritten notes — 600+ process steps, bypassed digital security. 5 years and 1.6T KRW of R&D transferred. [[IP leakage risk]] undermines [[Export controls]] effectiveness. Mixed for Korea thesis.
- Final test emerging as hidden bottleneck for AI chips. Larger packages (~120mm), higher heat → legacy equipment can't cope. Cohu (test handlers), ASE (OSAT) benefit. [[Final test bottleneck]]
- Severe DRAM/NAND shortage into 2026 — not just price, availability becoming an issue. Drivers: limited capacity, HBM taking DRAM wafers, cleanroom constraints. Bullish [[SK Hynix]], [[Samsung]] memory margins. [[Memory shortage 2025-2026]]
- [[Samsung]] showing metamaterial lens tech (NanoPrism) for image sensors at IEDM — first mass-market metamaterial optics. Shows Samsung has tech leadership in some areas despite foundry struggles. [[Image sensors]]
- xAI building Colossus 2 data center in Tennessee — 400MW near-term, 2GW path. Musk (Tesla + xAI) could be major [[Samsung]] anchor customer via Taylor fab. Bullish for Korea thesis. [[AI hyperscalers]]
- [[Rapidus]] (Japan's 2nm national champion) getting optimistic sentiment at SEMICON Japan. Suppliers confident in 2027 mass production. Small batch model — different from traditional high-volume. Japan emerging from "Lost 30 Years" in semis. [[Leading edge race]]
- [[NVIDIA]] acquired SchedMD (makers of SLURM workload scheduler). SLURM widely used by AI companies, universities, neoclouds. AMD/Intel users also depend on it. Expands [[CUDA moat]] to infrastructure layer. Bearish for [[AMD]] software efforts.
- [[Anthropic]] buying 400k TPUv7 (~$10B from [[Broadcom]]) + renting 600k through Google Cloud (~$42B). Deploying in own facilities with TeraWulf/Cipher Mining (Bitcoin miners pivoting to AI). Going TPU route, not NVIDIA. All flows to [[TSMC]]. [[AI hyperscalers]]
- Apple A19 achieves 10% die shrink on N3P (vs A18 on N3E) despite node only giving 4%. Rest from design: 2x cache density, layout efficiency. Highest volume leading edge chip. Shows [[Customer lock-in via co-design]] — Apple+TSMC co-optimization others can't match.
- Google TPUv8 dual path: "Sunfish" (Broadcom turnkey) vs "Zebrafish" (Google sources directly, MediaTek for supporting chips). Google escaping Broadcom's ~55% margin "tax" (~$15B/yr). Must cut ASIC costs to compete with [[NVIDIA]] Blackwell unit economics in 2026. [[Broadcom]] [[AI hyperscalers]]
- [[NVIDIA]] market positioning: Michael Burry disclosed puts (Nov 2025). Insider selling $496M in 90 days, zero insider buying. Bull case (53% margins, visibility to 2026) vs bear case (insiders cashing out). Sentiment indicator, not fundamental.
- Lam Research (LRCX) targeting $25-27B revenue by CY2028 (7-10% CAGR), $30B in $1T semi industry. WFE (wafer fab equipment) picks & shovels — benefits from fab buildout (TSMC, Samsung, Intel, Rapidus). Most fabs under construction, orders take time. [[Long WFE]]
- [[Applied Materials]] TSMC revenue +80% y/y FY25 (ATH), Samsung +31%, China -16%. TSMC = 40% of foundry/logic revenue. GAA revenue $4.5B, mostly TSMC. AMAT claims 50%+ GAA share, 30% incremental revenue per fab vs FinFET. GAA capacity to triple. [[Long WFE]]
- [[KLA]] services = 25% of revenue, 13% CAGR 2020-2025. Custom parts = customers can't self-service (lock-in). ASPs +150bps vs 2013. Equipment life: 12-13yrs → high teens now. 50K installed base growing. Recurring revenue annuity. [[Long WFE]]
- Wafer consumption data (Siltronic): Datacenter = 15% of total but 50% of 2025 incremental demand. Servers +23% y/y. Smartphones still biggest (22% share). PC recovering (+8%). Auto settling (+7%). Total wafer consumption +8% in 2025. Inventory headwinds decreasing. AI is THE demand driver. [[End market demand]]
- [[Broadcom]] concentration: Top 5 = 40% revenue, one distributor = 32%, Apple = $7B+, China = 17% ($7.6B). [[TSMC]] = 95% of wafers. Only $106M F26 purchase commitments — not fighting for capacity like others. Unusual flexibility or priority access?
- [[TSMC]] pricing power: Two eras. Pre-2019: ASP flat (0.1% CAGR), $1 COGS → $1.43 ASP ($0.43 profit). Post-2019: ASP +133% (15.2% CAGR), $1 COGS → $2.31 ASP ($1.31 profit). 3x incremental profit capture. Drivers: scarcity, EUV, HPC mix. Rising COGS discourages competition, widens moat. [[Long TSMC]]
- [[Micron]] segment profitability (GM fall-through): Mobile +64.5 pts (best, squeeze working), Auto +63.2, Cloud/AI +44.1 (accelerating), Core DC -127.2 (decelerating). Mobile shortage driving pricing power. [[Long memory]]
- STMicro SiC (silicon carbide for EVs): 2024 = $1.1B, 2025 transition year (decline), 2026 growth but below 2024, 2027 back to 2024 levels. Main customer (Tesla?) inventory correction, slower EV penetration. Confirms auto settling in [[End market demand]].
- [[Micron]] capex growing 4 straight years through FY27 — first time in 25+ years. Capital intensity dropping below 30% (vs 35% through-cycle guidance). FY26 2H weighted — aligns with semicap acceleration. Bullish [[Long memory]] and [[Long WFE]].
- [[Micron]] Q1 FY26 earnings: Rev $13.6B (+57% y/y) at 56.8% GM, guided Q2 $18.7B at 68% GM. FY26 capex raised to $20B. **Largest ever supply-demand gap — only meeting 50-67% of key customer demand.** Tightness through CY26+. CY26 HBM fully contracted. HBM TAM $100B by 2028 (40% CAGR). DRAM ASP +20% q/q. [[Long memory]] [[Memory shortage 2025-2026]]
- [[Broadcom]] non-AI semi revenue: First y/y growth in 9 quarters but still down 30% vs peak (~$6B → ~$4B). Non-AI now <40% of semi revenue (was 90% in 1QFY22). Wireless = lowest margin in non-AI, rest higher margin than XPU. No sharp recovery expected in F26. AI dependency deepening. [[End market demand]]
- [[TSMC]] annual price hikes: Told customers to expect increases starting Jan 1, 2026 through 2029. 2026: +3-10% depending on process node. Drivers: tight sub-3nm capacity, AI demand. Stock hit record NT$1,530, foreign institutions bought NT$9.27B. **Pricing power thesis validated — monopolist behavior.** [[Long TSMC]] [[Customer lock-in via co-design]]
- US data center power gap (Morgan Stanley): 69GW needed 2025-28, only 25GW available (10GW self-generated + 15GW grid spare). **44GW shortfall = 44 nuclear plants worth.** $2.6T for power + $2T for DCs = $4.6T to close gap. Power becoming hard constraint on AI buildout. May slow chip deployment even if supply exists. [[AI hyperscalers]] [[Power constraints]]
- Power constraint follow-up (Alex Portz): Hyperscalers already reduced expansion plans 18-24m ago. No line of sight to solving in US/Europe — too slow, too much red tape. **BYOP (Bring Your Own Power) is the new paradigm.** Mitigating factors: photonic interconnects (2-4x), efficient cooling (0.3-0.4x), specialist inference HW (2-4x) — but not enough to close gap. [[Power constraints]]
- [[Intel]] EMIB as CoWoS alternative: CoWoS capacity tight, only top AI makers can lock in. Marvell, [[MediaTek]] actively trying EMIB. Apple/Qualcomm adding "EMIB familiarity" to job posts. **New model: TSMC front-end + Intel back-end.** EMIB advantages: cheaper, good thermal, mature. US domestic production driver — TSMC back-end ships to Taiwan. Window may be temporary; if Intel misses it, [[ASE]]/Amkor/SPIL take the overflow. [[Advanced packaging]] [[Intel Foundry Services]]
- [[NVIDIA]] H200 China exports resuming (Counterpoint): Could recover 10-25% China share (was 95% → ~0%). **US strategic calculus**: H200 is "previous gen" — B200 is 3.1x faster, Rubin 2026 widens gap further. Release old tech while monopolizing cutting edge. Even "outdated" H200 beats Chinese chips: Huawei 910C = 76% compute, 2/3 memory bandwidth. **Dual ecosystem forming**: NVIDIA for training (high barriers), Chinese for inference (cost sensitive). China's response: ASIC differentiation, full-stack ecosystem. Challenges: [[TSMC]] access restricted, SMIC yield issues. [[Export controls]] [[CUDA moat]]
- [[Samsung]] Exynos packaging: Developing SbS (Side-by-Side) structure — AP and DRAM horizontal instead of vertical (PoP). Benefits: thinner package, thicker chips (better thermal), shorter signal paths. Exynos 2600 (Galaxy S26) has HPB (Heat Path Block) reducing heat 30%. SbS tradeoff: larger package area → foldables first. Path to 3D packaging with direct Cu-Cu bonding. Called FOWLP-SbS. [[Advanced packaging]]
- **InP substrate shortage**: New bottleneck for AI optical interconnects. Even 20-30% capacity increases not keeping pace. Gap widening, may not balance until 2026+. Supply concentrated: Sumitomo (Japan), AXT (US but China mfg). China export controls on gallium/germanium/InP raw materials. Workarounds: "Epi-only" model (customers supply substrates), recycled wafers. IntelliEPI (US, Texas) expanding 50% by 2027, CHIPS Act eligible. **Materials layer becoming constraint, not just fabs.** [[AI hyperscalers]] [[Supply chain bottlenecks]]
- **Memory shortage at brand level**: Prices up 4-5x y/y. PC brands expected contracts by Q3 2025 — none signed by year-end. Seller's market, suppliers won't commit. **Priority customers**: Apple (230M iPhones, 20M MacBooks, stable contracts), Lenovo (Samsung relationship), Asus (Samsung reciprocal from OLED), Dell (AI servers, US govt/military, Micron). Brands responding: pass costs to consumers, downgrade specs. Continues into 2026. [[Long memory]] [[Memory shortage 2025-2026]]
- **Hyperscaler custom chip roadmap** (HSBC/TrendForce): All moving to 3nm/2nm at [[TSMC]]. IC design: [[Broadcom]] dominates but [[MediaTek]] appearing (Google TPUv7e, Microsoft Maia 400, Bytedance APU). New entrants: [[xAI]] X1 (3nm, 2027), OpenAI Titan (3nm/2nm), [[Apple]] Belta (3nm, 2027), Softbank Gen1/2. All need HBM3e/HBM4. **Key insight**: Custom silicon wave validates both [[Long TSMC]] (all fab there) and [[Long memory]] (all need HBM). Broadcom risk: MediaTek gaining share. [[AI hyperscalers]]
- **TrendForce 2026 AI Server report**: DRAM supply tightening, broad-based price increases through 2026. Supply shifting to high-margin server products → PC/mobile get "passive price increases" (squeezed out). Enterprise SSD demand strong (HDD substitution). **"Profitability-first strategy" keeping prices on upward trajectory.** Structural, not cyclical. [[Long memory]] [[Memory shortage 2025-2026]]
- **[[SK Hynix]] M15X expansion**: Second cleanroom entering hook-up design (final stage before equipment). First cleanroom opened Oct 2025, **2 months ahead of schedule**, producing HBM3E/4 DRAM. Adding 1c DRAM lines (6th gen). Production scaling to 55K-60K wafers/month (from 35K target). **M8 P&T6 packaging fab**: few months from operation, will do TSV and vertical stacking for HBM. Converting old image sensor fab to advanced packaging. [[Long memory]] [[Advanced packaging]]
- **HBM vs general DRAM profitability** (Korea analysts): DDR5 price now $12-13/GB vs HBM4 ~$15/GB — gap narrowing. UBS: general DRAM gross margin could **temporarily exceed HBM** in 2025-2026. KB Securities: DDR5 margins may overtake HBM3E next year. Some general DRAM products hitting ~70% operating margin. **Strategy divergence**: SK Hynix HBM-centric (EUV priority for HBM), Samsung "mix strategy" (HBM4 + GDDR7/LPDDR5X flexibility). 2026 OP forecasts: Samsung ~82-100T won, SK Hynix ~74-90T won. Samsung's higher general DRAM share = greater operating leverage. [[Samsung]] [[SK Hynix]] [[Long memory]]
- **[[TSMC]] Kumamoto Fab 2 pivoting to 2nm** — Scrapping original 6nm plan, jumping straight to 2nm for autonomous driving and AI chips. JASM posted NT$6.2B loss H1 2025 vs Arizona's NT$4.7B profit. Japan fab struggling while US fab profitable. [[Leading edge race]]
- **[[TSMC]] Nanjing VEU expiring Dec 31** — TSMC dismisses concerns, says Chinese clients can access advanced nodes across global network. Xiaomi 3nm XRING O1 chip cited as proof. [[Export controls]]
- **[[TSMC]] market share now 71%** (was 70% in Q2). Foundry 2.0 market hit $84.8B in Q3 2025, +17% y/y.
- **[[Samsung]] potential NVIDIA second foundry** — After Groq licensing deal with NVIDIA, industry sources say NVIDIA may be exploring Samsung as backup to TSMC. Major potential win. [[Can Samsung ever catch TSMC]]
- **[[Samsung]] Taylor fab 93.6% complete**, targeting July 2026. Now planning 50,000 wafers/month 2nm (up from 20,000). All 4nm plans scrapped, going full 2nm.
- **[[Samsung]] Exynos 2600 announced** — World's first 2nm mobile chip (SF2 GAA process) for Galaxy S26. Proof point for 2nm viability. [[Leading edge race]]
- **[[SK Hynix]] M15X starting 4 months early** — Feb 2026 vs June original. Dedicated to HBM4 for NVIDIA Rubin. Accelerating to meet demand. [[Long memory]]
- **HBM4 paid samples delivered to NVIDIA** — Both [[Samsung]] and [[SK Hynix]] moved beyond free prototypes to pre-contract commercial phase. Q1 2026 contract finalization expected. [[Long memory]]
- **HBM3E prices up ~20% for 2026** — Driven by H200 China approval + tight supply. Samsung and SK Hynix both raising prices. [[Long memory]] [[Memory shortage 2025-2026]]
- **Memory gross margins to exceed [[TSMC]] in Q4 2025** — First time since Q4 2018. Samsung/SK Hynix expected 63-67% GM vs TSMC. Memory cycle turning. [[Long memory]]
- **[[NVIDIA]] $20B Groq acquisition** — Largest deal ever. Acquiring LPU tech (10x faster, 1/10th energy for inference). "Acqui-hire" of founder Jonathan Ross. Entering non-GPU inference market. [[CUDA moat]]
- **[[NVIDIA]] H200 approved for China with 25% US govt cut** — Shipping before Lunar New Year. Strategic release of "old" tech while monopolizing cutting edge.
- **[[NVIDIA]] $275B backlog for 2026** — Massive demand visibility.
- **[[Intel]] 18A reached HVM** — "5 nodes in 4 years" roadmap complete. First to combine RibbonFET (GAA) + PowerVia (backside power). Panther Lake launching Jan 2026. [[Intel Foundry Services]]
- **US govt took 9.9% equity stake in [[Intel]]** — Converted $8.9B CHIPS grants to equity + $3B DoD "Secure Enclave" contract. Government now permanent stakeholder. [[CHIPS Act]]
- **[[NVIDIA]] halted [[Intel]] 18A testing** — Reuters: NVIDIA evaluated but stopped moving forward. Setback for Intel foundry ambitions. [[Intel Foundry Services]] [[Will Intel Foundry Services succeed]]
- **[[Intel]] customers: Microsoft Maia 2 + Amazon custom chips** — Some wins despite NVIDIA setback. [[Intel Foundry Services]]
- **[[Intel]] stock up 86% YTD** despite $9.5B operating loss. Market pricing in turnaround hopes.

### AI Race research (new index)

- **Hyperscaler capex 2026: $600B** (+36% y/y), 75% tied to AI. Amazon $125B, Meta $110B, Google $91-93B, Microsoft $35B/quarter. **Capex at 94% of operating cash flows** — borrowing to fund AI. Unsustainable unless AI monetizes. [[AI hyperscalers]]
- **[[OpenAI]] expects $74B cumulative losses through 2028**, profitable by 2030. Revenue $13B but burning cash at 57% of revenue through 2027. [[Model lab economics]]
- **[[Anthropic]] more capital efficient** — $9B revenue, break-even target 2028, burn rate dropping to 9% of revenue by 2027. OpenAI burning 14x more cash. [[Model lab economics]]
- **Open source gap closed to 0.3 percentage points** on MMLU (was 17.5 pts one year ago). DeepSeek-V3.2 won IMO Gold, IOI Gold, ICPC 2nd. Frontier performance at **10-30x cheaper** ($0.27 vs $15-30 per million tokens). [[Open source commoditization]]
- **95% of enterprises NOT seeing meaningful ROI** from AI (MIT survey). $37B enterprise AI spend in 2025, but VCs keep predicting "next year is the year." Coding = 55% of departmental AI spend. [[Enterprise AI adoption]]
- **Inference pricing deflationary** — GPT-5 $30/$60, Claude Opus $15/$75, DeepSeek $0.27/$1.10 per million tokens. 10-30x price gap. Commoditization accelerating. [[Inference economics]]
- **Agentic AI market: $7.9B in 2025**, projected $236B by 2034. 35% already using agents, 66% seeing measurable value. 171% average projected ROI. Gartner: 40% of enterprise apps will have agents by 2026 (up from <5%). [[Agentic AI]]
- **Goldman Sachs piloting Devin** alongside 12,000 human developers. Cognition Labs valued at $4B. Devin 2.0 dropped to $20/month. Reality: ~15% of complex tasks completed without assistance. Agents augment, not replace. [[Agentic AI]]
- **Refined trade implications**: AI is bifurcating. Coding + agents = working (bullish). Generic enterprise AI = struggling (bearish). Model labs diverge — Anthropic winning with agents/enterprise, OpenAI burning cash on consumer. Infrastructure wins regardless.

## Links touched

- [[Foundry Wars]] — created as index
- [[Why TSMC can afford patience]] — new concept note
- [[Why Samsung's aggression may be rational]] — reframed from "dysfunction" to "rational asymmetric betting"

## Questions surfaced

- Should I add [[ASML]] as an actor? Equipment bottleneck affects everyone
- What about [[Advanced packaging]] — another TSMC moat worth tracking?
- How do I want to track news sources for claims in these notes?

---

## Thesis implications

**[[Long TSMC]]:** Multiple validation points — 71% market share, pricing power confirmed (3-10% hikes through 2029), all hyperscaler custom chips fab there. Kumamoto pivot to 2nm shows demand pull.

**[[Long memory]]:** Memory gross margins exceeding TSMC for first time since 2018. HBM prices +20%. DDR5 margins temporarily above HBM. Structural shortage through 2026.

**[[Long WFE]]:** AMAT, LRCX, KLA all showing strength. TSMC 40% of foundry equipment. GAA capacity tripling. Multi-year capex expansion at Micron. Services/recurring revenue moats growing.

**[[Can Samsung ever catch TSMC]]:** Mixed signals. Taylor fab pivoting to 2nm. Exynos 2600 = first 2nm mobile chip proof point. But foundry share down to 6.8%. Potential NVIDIA second-source is major upside.

**[[CUDA moat]]:** Expanded — NVIDIA acquired SLURM scheduler. H200 returning to China. $275B backlog. Groq acquisition adds inference. But AMD NodAI gives them "non-zero chance" on software.

**[[Intel Foundry Services]]:** 18A reached HVM but NVIDIA halted testing. Microsoft and Amazon custom chips are wins. US govt 9.9% stake. EMIB as CoWoS alternative gaining traction.

---

## Open threads

- [ ] InP substrate shortage — new bottleneck emerging for optical interconnects
- [ ] Power gap: 44GW shortfall by 2028 — may constrain AI deployment
- [ ] Intel EMIB as TSMC back-end alternative — window may be temporary
- [ ] MediaTek gaining share from Broadcom on hyperscaler custom chips
- [ ] Samsung Exynos 2600 2nm results — proof point for yield claims
- [ ] Open source AI closing gap — DeepSeek 10-30x cheaper, implications for model economics

---

#daily

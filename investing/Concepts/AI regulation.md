# AI regulation

#concept #ai #policy #regulation

**AI regulation** — Global race to govern AI. EU leads with comprehensive risk-based law; US fragmented (states vs federal preemption); China controls content/algorithms; Brazil building LatAm model. 2026 is implementation year.

---

## Global landscape

| Jurisdiction | Framework | Approach | Status | Extraterritorial |
|--------------|-----------|----------|--------|------------------|
| **[[EU]]** | EU AI Act | Risk-based, comprehensive | **Law** (high-risk Aug 2026) | Yes |
| **[[Brazil]]** | Marco Legal (PL 2338) | Risk-based, social inclusion | Bill (in Chamber) | TBD |
| **[[China]]** | Multiple regulations | Content control, algorithmic | **Law** (multiple in force) | Limited |
| **[[UK]]** | Pro-innovation | Sector-specific, principles | Framework (no horizontal law) | No |
| **US Federal** | None (preemption push) | Deregulatory | Proposal stage | N/A |
| **US States** | Colorado, California | Patchwork | **Law** (2026) | No |
| **[[India]]** | None | Advisory only | Draft rules | No |
| **[[Singapore]]** | Model Framework | Voluntary, governance | Guidance | No |
| **International** | OECD, UNESCO | Principles | Soft law | N/A |

---

## Regulatory approaches compared

| Approach | Jurisdictions | Philosophy |
|----------|---------------|------------|
| **Comprehensive/horizontal** | EU, Brazil | One law covering all AI |
| **Sector-specific** | UK, US (proposed) | Existing regulators adapt |
| **Content/algorithmic control** | China | State control of information |
| **Disclosure/transparency** | California | Label AI, don't restrict it |
| **Consequential decisions** | Colorado | Focus on high-stakes uses |
| **Voluntary/principles** | Singapore, OECD | Industry self-governance |

---

## 2026 regulatory calendar

| Law | Effective | Jurisdiction | Focus |
|-----|-----------|--------------|-------|
| **California AI Transparency Act** | Jan 1, 2026 | California | AI content disclosure |
| **Colorado AI Act** | Jun 30, 2026 | Colorado | High-risk AI systems |
| **EU AI Act (high-risk)** | Aug 2, 2026 | European Union | High-risk requirements |

---

## EU AI Act

**World's first comprehensive AI law.**

### Timeline

| Date | Milestone |
|------|-----------|
| Aug 2024 | Entered into force |
| Feb 2025 | Prohibited AI practices apply |
| Aug 2025 | GPAI model rules apply |
| **Aug 2026** | **High-risk system requirements apply** |
| Aug 2027 | All systems must comply |

### Risk categories

| Category | Examples | Requirements |
|----------|----------|--------------|
| **Unacceptable** | Social scoring, manipulative AI | Banned |
| **High-risk** | Medical devices, employment, credit | Strict compliance |
| **Limited** | Chatbots, deepfakes | Transparency only |
| **Minimal** | Spam filters, games | No requirements |

### High-risk requirements (Aug 2026)

| Requirement | Detail |
|-------------|--------|
| Risk management | Ongoing assessment systems |
| Data governance | Training data quality standards |
| Technical documentation | Full system documentation |
| Record-keeping | Automatic logging |
| Transparency | Clear user information |
| Human oversight | Meaningful human control |
| Accuracy | Performance standards |
| [[Cybersecurity]] | Robustness requirements |

### Penalties

| Violation | Fine |
|-----------|------|
| Prohibited AI | Up to €35M or 7% global revenue |
| High-risk non-compliance | Up to €15M or 3% global revenue |
| Misinformation to authorities | Up to €7.5M or 1% global revenue |

---

## Colorado AI Act

**First comprehensive US state AI law.**

### Effective date

Originally Feb 1, 2026 → **Extended to Jun 30, 2026**

### Scope

Applies to "high-risk" AI systems making consequential decisions about:
- Employment
- [[Housing]]
- Credit/lending
- Education
- [[Healthcare]]

### Requirements

| Party | Obligation |
|-------|------------|
| **Developers** | Document risks/limitations, disclose to deployers |
| **Deployers** | Annual impact assessments, consumer notice, opt-out rights |
| **Both** | Risk disclosure, impact documentation |

### Key provisions

| Requirement | Detail |
|-------------|--------|
| Impact assessments | Annual, documented |
| [[Consumer]] notice | Disclose AI use in decisions |
| Opt-out rights | For high-risk applications |
| Risk disclosure | Known and foreseeable risks |

---

## California AI laws (2026)

### AI Transparency Act (SB 942)

| Detail | Value |
|--------|-------|
| Effective | Jan 1, 2026 |
| Scope | AI systems with 1M+ monthly CA visitors |
| Requirement | Disclose AI-generated/modified content |
| Penalty | $5,000/violation/day |

### Training Data Transparency (AB 2013)

| Detail | Value |
|--------|-------|
| Effective | Jan 1, 2026 |
| Scope | Public generative AI systems |
| Requirement | High-level summary of training datasets |
| Goal | Transparency on copyright, privacy, bias risks |

### Frontier AI Act (SB 53)

| Detail | Value |
|--------|-------|
| Effective | Jan 1, 2026 |
| Scope | Frontier AI models |
| Requirement | Safety assessments, incident reporting |

---

## Brazil — Marco Legal (PL 2338/2023)

**LatAm's first comprehensive AI framework.** Modeled on EU AI Act but emphasizes social inclusion and fairness.

| Milestone | Date |
|-----------|------|
| Introduced | 2023 |
| Senate approval | December 10, 2024 |
| Sent to Chamber | March 17, 2025 |
| Special committee | April 29, 2025 |
| **Status** | **In Chamber of Deputies** |

### Key provisions

| Element | Description |
|---------|-------------|
| Risk classification | Tiered system (like EU) |
| Civil liability | Rules for AI-caused harm |
| SIA | National System for AI Regulation and Governance |
| LGPD integration | Parallel with data protection law |
| Social inclusion | Unique LatAm emphasis |

### Comparison with EU AI Act

| Aspect | EU AI Act | Brazil Marco Legal |
|--------|-----------|-------------------|
| Risk tiers | 4 (unacceptable → minimal) | Similar tiered approach |
| Social focus | Limited | **Strong** (fairness, inclusion) |
| Penalties | Up to 7% global revenue | TBD |
| Status | Law (phasing in) | Bill |
| GDPR/LGPD link | Parallel | Explicit integration |

**Political context:** Lula pushing before 2026 elections. If passed, becomes model for Argentina, Chile, Colombia.

See [[Brazil AI]] for full detail including REDATA infrastructure incentives.

---

## China — Algorithmic & content control

**Multiple overlapping regulations** — not one comprehensive law, but layered control.

| Regulation | Effective | Focus |
|------------|-----------|-------|
| Algorithm Recommendation Regulation | Mar 2022 | Recommendation algorithms |
| Deep Synthesis Regulation | Jan 2023 | Deepfakes, synthetic media |
| Generative AI Measures | Aug 2023 | ChatGPT-like services |
| AI Safety Governance Framework | Sep 2024 | Risk classification |

### Key requirements

| Requirement | Detail |
|-------------|--------|
| Content alignment | Must reflect "core socialist values" |
| Algorithm registration | File with CAC (Cyberspace Administration) |
| Real-name verification | Users must be identified |
| Labeling | AI-generated content must be marked |
| Training data | No illegal content, IP violations |
| Security assessments | Required before launch |

### Philosophy vs West

| Aspect | China | EU/US |
|--------|-------|-------|
| Primary concern | **State control, social stability** | Safety, rights, innovation |
| Content rules | Prescriptive (socialist values) | Proscriptive (ban harms) |
| Enforcement | Proactive, licensing | Reactive, penalties |
| Innovation stance | Controlled development | Permissionless (US) / regulated (EU) |

**Investment implication:** Foreign AI companies cannot operate freely in China. Domestic champions ([[Baidu]], [[Alibaba]], [[Tencent]], [[ByteDance]]) have regulatory moat.

---

## UK — Pro-innovation framework

**No horizontal AI law.** Sector regulators adapt existing rules.

| Element | Detail |
|---------|--------|
| White Paper | March 2023 |
| Approach | Principles-based, sector-specific |
| Central body | None (regulators coordinate) |
| Legislation | Not planned |

### Five principles (non-binding)

1. Safety, security, robustness
2. Transparency and explainability
3. Fairness
4. Accountability and governance
5. Contestability and redress

### Sector regulators responsible

| Regulator | Domain |
|-----------|--------|
| FCA | Financial services AI |
| Ofcom | Communications AI |
| CMA | Competition/markets |
| ICO | Data protection |
| MHRA | Medical devices |

**Philosophy:** "Regulate the use, not the technology." Avoid EU-style horizontal law. Post-Brexit divergence from EU AI Act.

**Risk:** UK companies serving EU customers still must comply with EU AI Act.

---

## International frameworks

### OECD AI Principles (2019, updated 2024)

| Principle | Description |
|-----------|-------------|
| Inclusive growth | Benefit people and planet |
| Human-centered values | Respect human rights |
| Transparency | Explainable AI |
| Robustness | Safe and secure |
| Accountability | Responsibility for AI systems |

**Signatories:** 46 countries including US, UK, EU members, Japan, Korea, Brazil, Argentina, Chile, Mexico.

Not legally binding but influential — referenced in national frameworks.

### UNESCO AI Ethics Recommendation (2021)

| Element | Detail |
|---------|--------|
| Adopted | November 2021 |
| Signatories | 193 member states |
| Focus | Human rights, ethics, sustainability |
| Binding | No (recommendation) |

Brazil engaged with UNESCO RAM (Readiness Assessment Methodology).

### G7 Hiroshima AI Process (2023)

Voluntary code of conduct for frontier AI developers. Endorsed by major AI labs.

---

## Comparison

### Comprehensive frameworks

| Aspect | EU AI Act | Brazil Marco Legal | China |
|--------|-----------|-------------------|-------|
| **Scope** | All AI systems | All AI systems | Algorithms, GenAI, deepfakes |
| **Approach** | Risk-based tiers | Risk-based + social | Content control |
| **Penalties** | Up to 7% global revenue | TBD | Licensing revocation |
| **Status** | Law (phasing in) | Bill | Multiple laws in force |
| **Philosophy** | Rights protection | Inclusion + rights | State stability |

### US landscape

| Aspect | Federal (proposed) | Colorado | California |
|--------|-------------------|----------|------------|
| **Scope** | Preemption of states | High-risk decisions | Content/transparency |
| **Approach** | Lightweight standard | Consequential decisions | Disclosure-focused |
| **Penalties** | TBD | TBD | $5K/day/violation |
| **Status** | Proposal | Law (Jun 2026) | Law (Jan 2026) |

### Liability models

| Jurisdiction | Liability approach |
|--------------|-------------------|
| EU | Strict liability for high-risk; AI Liability Directive pending |
| Brazil | Civil liability rules in Marco Legal |
| US | Existing tort law; no AI-specific liability |
| China | Platform liability for content |
| UK | Existing sector rules |

---

## Convergence and divergence

### Where frameworks converge

| Element | Adoption |
|---------|----------|
| Risk-based classification | EU, Brazil, China, Colorado |
| Transparency/disclosure | All major frameworks |
| Human oversight requirements | EU, Brazil, China (for some uses) |
| High-risk use case focus | EU, Colorado, Brazil |
| OECD principles reference | EU, Brazil, UK, US (executive orders) |

### Where they diverge

| Dimension | Divergence |
|-----------|-----------|
| **Content control** | China prescriptive; West proscriptive |
| **Centralization** | EU/Brazil horizontal; UK/US sectoral |
| **Innovation stance** | US permissionless; EU precautionary; China controlled |
| **Extraterritoriality** | EU yes; others limited |
| **Social goals** | Brazil explicit; others implicit |
| **Enforcement** | EU fines; China licensing; US litigation |

### The Brussels Effect

EU AI Act likely to become de facto global standard (like GDPR) because:
- Extraterritorial reach — applies to non-EU companies serving EU
- Compliance cost — easier to build one global product than regional variants
- First-mover — most detailed framework

**But:** US pushing back (Sacks), China has own ecosystem, UK deliberately diverging.

---

## Investment implications

### Compliance costs

| Company type | Impact |
|--------------|--------|
| **AI developers** | Documentation, testing, auditing |
| **AI deployers** | Impact assessments, disclosures |
| **Foundational model cos** | Training data transparency |

### Winners

| Category | Why |
|----------|-----|
| **AI compliance tools** | New compliance market |
| **AI auditing firms** | Mandatory assessments |
| **Explainable AI** | Transparency requirements |

### Affected companies

| Company | Exposure |
|---------|----------|
| [[OpenAI]] | All three jurisdictions |
| [[Anthropic]] | All three jurisdictions |
| [[Google]] | All three jurisdictions |
| [[Microsoft]] | All three jurisdictions |
| [[Meta]] | All three jurisdictions |

---

## Trump administration federal preemption push (Jan 2026)

**The problem:** Over **1,200 AI bills** going through state legislatures simultaneously ([[David Sacks]], Davos Jan 23). Many are "knee-jerk reactions" to hypothetical concerns before seeing how AI is actually used.

**Why it matters:** Patchwork is most detrimental to early-stage companies and entrepreneurs — large companies can navigate 50 different rules, startups cannot. This stifles precisely the permissionless innovation that makes Silicon Valley work.

| Element | Detail |
|---------|--------|
| Executive order | Dec 2025 — directed work on national framework proposal |
| Congressional path | Need 60 Senate votes — must be bipartisan |
| Pushback heard | "Can't replace something with nothing" — need federal standard, not just preemption |
| States keep | Child safety regulation, data center permitting |
| Interest level | "Quite a bit of interest" in both House and Senate (Sacks, Jan 2026) |
| Working on | Legislative proposal for "lightweight federal standard" |
| Lead | [[David Sacks]] + [[Michael Kratsios]] together |

**Sacks on regulatory philosophy:**
- Biden left 300 pages of AI/semiconductor regulations — would have changed "permissionless innovation" to "go to Washington for approval"
- Trump rescinded all in first week
- Since then: pro innovation, pro infrastructure, pro energy, pro export
- "Since Hewlett and Packard started 85 years ago... founders don't need to go to Washington to get permission for their idea"

**AI optimism gap ([[Stanford]] polling):**

| Country | "AI more beneficial than harmful" |
|---------|-----------------------------------|
| [[China]] | **83%** |
| US | **39%** |

Asian countries high, Western countries low. Sacks attributes to: (1) media doom/gloom, (2) Hollywood dystopian portrayals, (3) tech leaders talking about eliminating jobs. Low AI optimism feeds regulatory frenzy — could "shoot ourselves in the foot" and cost the race.

**EU criticism (Sacks):** "Bad case of main character syndrome" — when EU talks about AI leadership, they mean regulators showing the regulatory model. "Regulators are supporting players. The main characters always have to be the entrepreneurs." EU AI Act passed before [[ChatGPT]] existed.

*Source: Davos panel (Sacks, Kratsios, Bartiromo), Jan 23 2026*

---

## What to watch

### Global
- [ ] **Brazil Marco Legal** — Chamber vote (2026 election pressure)
- [ ] **EU AI Act** — high-risk requirements (Aug 2026)
- [ ] **China** — next wave of generative AI rules
- [ ] **UK** — whether pro-innovation stance holds
- [ ] **India** — draft rules finalization

### US
- [ ] **Federal preemption legislation** — Sacks/Kratsios working on in 2026
- [ ] **1,200+ state bills** — regulatory frenzy trajectory
- [ ] Colorado enforcement rules (Jun 2026)
- [ ] California AG enforcement actions
- [ ] Other state AI laws (Texas, Illinois pending)

### International
- [ ] OECD principles update
- [ ] G7 Hiroshima Process evolution
- [ ] Cross-border certification recognition

---

## Related

### Jurisdictions
- [[EU]] — AI Act originator, Brussels Effect
- [[Brazil AI]] — Marco Legal + REDATA, LatAm model
- [[China]] — algorithmic/content control regime
- [[UK]] — pro-innovation, sector-specific
- [[Singapore Tech]] — voluntary Model Framework
- [[India]] — advisory rules only

### US Policy
- [[Trump II]] — federal AI policy direction
- [[David Sacks]] — leading federal preemption push
- [[Michael Kratsios]] — US CTO, co-leading preemption effort

### International
- [[OECD]] — AI Principles (46 signatories)
- UNESCO — AI Ethics Recommendation

### Affected actors
- [[OpenAI]] — high exposure (all jurisdictions)
- [[Anthropic]] — high exposure
- [[Google]] — high exposure
- [[Microsoft]] — high exposure
- [[Meta]] — high exposure
- [[Baidu]] — China compliance advantage
- [[Alibaba]] — China compliance advantage

### Concepts
- [[AI Infrastructure]] — deployment affected by regulation
- [[Export controls]] — AI chip restrictions (different vector)
- [[LGPD]] — Brazil data protection (Marco Legal integration)
- [[GDPR]] — EU data protection (AI Act parallel)

---

## Sources

- [National Law Review: 2026 Outlook AI](https://natlawreview.com/article/2026-outlook-artificial-intelligence)
- [Greenberg Traurig: 2026 Outlook AI](https://www.gtlaw.com/en/insights/2025/12/2026-outlook-artificial-intelligence)
- [Colorado General Assembly: SB24-205](https://leg.colorado.gov/bills/sb24-205)
- [Schellman: Colorado AI Act](https://www.schellman.com/blog/ai-services/what-you-need-to-know-about-the-colorado-ai-act)

*Created 2026-01-14, updated 2026-01-31*

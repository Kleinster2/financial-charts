---
aliases:
  - ARC-AGI-2
  - ARC Prize
  - Abstract and Reasoning Corpus
tags:
  - concept
  - ai
  - benchmark
---

# ARC-AGI

Benchmark measuring fluid intelligence — ability to reason about novel abstract problems without memorized knowledge. Grid-based visual puzzles with few input-output examples; model must infer transformation rules through abstraction. Created by [[Francois Chollet]] (Keras creator), launched 2019.

ARC-AGI-2 (2025) added harder tasks with deeper concept recombination and multi-step compositional reasoning.

---

## Why it matters

Remained largely unsolved from 2019 until late 2024. Four frontier labs ([[Anthropic]], [[Google DeepMind]], [[OpenAI]], [[xAI]]) now report ARC-AGI scores in public model cards. On ARC-AGI-2, best models score ~50-70% vs ~100% for humans — genuine generalization remains far from solved.

---

## Current scores (Feb 2026)

| Model | ARC-AGI-2 |
|-------|-----------|
| [[Claude Opus]] 4.6 | 68.8% |
| [[Claude Opus]] 4.5 | 37.6% |
| [[ChatGPT]] GPT-5.2 | 52.9% |
| Human | ~100% |

---

## Related

- [[AI benchmarks]] — parent concept
- [[Francois Chollet]] — creator
- [[Frontier models]] — primary subjects

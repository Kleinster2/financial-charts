#concept #ai #models

# Model Landscape

Comparative view of major AI model families. For investment implications, see the company notes.

---

## Frontier models (closed)

| Family | Company | Latest | Strength |
|--------|---------|--------|----------|
| **GPT** | [[OpenAI]] | GPT-4o, o1, o3 | Reasoning, multimodal, brand |
| **[[Claude]]** | [[Anthropic]] | [[Claude]] 4 (Opus/Sonnet) | Coding, safety, long context |
| **[[Gemini]]** | [[Google]] | [[Gemini]] 2.0 | Multimodal, integration |
| **[[Grok]]** | [[xAI]] | [[Grok]] 3 | Real-time data (X), speed |

**Common traits**: API access, usage-based pricing, rapid iteration, enterprise focus.

### Emerging labs (pre-product)

| Lab | Valuation | Focus | Status |
|-----|-----------|-------|--------|
| [[Recursive]] | ~$4B (talks) | Self-improving [[Superintelligence]] | Fundraising |
| [[SSI]] | ~$1B | Safe superintelligence | Stealth |

New entrants betting on next-generation architectures beyond current transformer scaling.

---

## Open weights models

| Family | Company | Latest | Strength |
|--------|---------|--------|----------|
| **[[Llama]]** | [[Meta]] | [[Llama]] 3.3 | Scale, community, fine-tuning |
| **[[Mistral]]** | [[Mistral]] AI | [[Mistral]] Large 2 | Efficiency, European |
| **[[Qwen]]** | [[Alibaba]] | [[Qwen]] 2.5 | [[China]] open-source leader |
| **[[DeepSeek]]** | [[DeepSeek]] | [[DeepSeek]]-V3 | MoE efficiency, cost |
| **[[GLM]]** | [[Zhipu]] AI | [[GLM]]-4 | [[China]] bilingual |

**Common traits**: Downloadable weights, self-hosting, fine-tuning allowed, varied licensing.

---

## [[China]] closed models

| Family | Company | Latest | Notes |
|--------|---------|--------|-------|
| **[[Ernie]]** | [[Baidu]] | [[Ernie]] 4.0 | First mover, search integrated |
| **[[Doubao]]** | [[ByteDance]] | [[Doubao]] Pro | Fastest growing, [[TikTok]] parent |
| **[[Hunyuan]]** | [[Tencent]] | [[Hunyuan]] | WeChat integrated |
| **Tongyi Qianwen** | [[Alibaba]] | [[Qwen]] Max | Cloud integrated |

**Dynamics**: Catching up to US frontier. Constrained by [[Export controls]] limiting training compute.

---

## Capability tiers (as of early 2026)

| Tier | Models | Characteristics |
|------|--------|-----------------|
| **Frontier** | GPT-4o, [[Claude]] Opus, [[Gemini]] Ultra, o3 | Best benchmarks, highest cost |
| **Near-frontier** | [[Claude]] Sonnet, [[Gemini]] Pro, [[Llama]] 405B | 90% capability, better economics |
| **Efficient** | [[Mistral]], [[Qwen]], smaller [[Llama]] | Good enough for most tasks |
| **Specialized** | Codex, Med-PaLM, legal models | Domain-specific fine-tunes |

---

## Key differentiators

| Dimension | Leaders | Laggards |
|-----------|---------|----------|
| **Reasoning** | o3, [[Claude]] Opus | Most open models |
| **Coding** | [[Claude]], GPT-4 | [[China]] models |
| **Multimodal** | [[Gemini]], GPT-4o | Text-only models |
| **Long context** | [[Claude]] (200K), [[Gemini]] (1M+) | Most others |
| **Speed** | [[Groq]]-hosted, [[Grok]] | Large reasoning models |
| **Cost/token** | [[DeepSeek]], [[Mistral]] | Frontier closed models |
| **Safety** | [[Claude]], GPT | Open models (by design) |

---

## Open vs closed dynamics

**Closed advantages**:
- Faster iteration (no weight leakage)
- Better safety controls
- Enterprise trust
- Recurring revenue model

**Open advantages**:
- Community innovation
- Self-hosting (data privacy)
- Fine-tuning flexibility
- No vendor lock-in
- [[China]] access (circumvents some restrictions)

**Trend**: Gap narrowing. [[Llama]] 3.3 approaches GPT-4 on many benchmarks.

---

## Investment implications

| Thesis | Models involved |
|--------|-----------------|
| [[Long Anthropic]] | [[Claude]] differentiation |
| [[Long NVIDIA]] | All models need GPUs |
| [[Export controls]] | [[China]] models constrained |
| [[Inference disaggregation]] | Model serving economics |
| [[Open source commoditization]] | [[Llama]], [[Qwen]] pressure margins |

**The real question**: Does model capability translate to company economics? See [[Model lab economics]].

---

## Model economics

| Model type | Training cost | Inference margin | Moat |
|------------|---------------|------------------|------|
| Frontier closed | $100M+ | High (70%+) | Capability + brand |
| Near-frontier closed | $10-50M | Medium (50-70%) | Integration |
| Open weights | $10-100M | Zero (no API) | Community, fine-tunes |

**Commoditization risk**: As open models approach frontier, closed model pricing power erodes.

---

## Tracking model releases

| Company | Typical cadence | Next expected |
|---------|-----------------|---------------|
| OpenAI | 6-12 months | GPT-5 (2026?) |
| Anthropic | 6-9 months | [[Claude]] 4.5? |
| Google | 6-12 months | [[Gemini]] 2.5? |
| Meta | 12-18 months | [[Llama]] 4 |

---

*Updated 2026-01-28*

---

## Related

- [[OpenAI]] — GPT family
- [[Anthropic]] — [[Claude]] family
- [[Google]] — [[Gemini]] family
- [[Meta]] — [[Llama]] (open weights)
- [[Baidu]] — [[Ernie]] ([[China]] leader)
- [[xAI]] — [[Grok]]
- [[Alibaba]] — [[Qwen]] (open weights)
- [[ByteDance]] — [[Doubao]] (fastest growing [[China]])
- [[Recursive]] — emerging (self-improving AI)
- [[SSI]] — emerging (safe superintelligence)
- [[Export controls]] — constrains [[China]] training
- [[Model lab economics]] — business model dynamics
- [[Superintelligence]] — long-term goal
- [[Open source commoditization]] — margin pressure thesis
- [[Inference disaggregation]] — serving economics

---
aliases: [China open source AI, Chinese open-weight models]
---

China's open-weight AI models now dominate the open ecosystem — 5 of top 15 open models are Chinese.

## Key players

| Company | Model | Notes |
|---------|-------|-------|
| [[DeepSeek]] | R1, V3 | Kicked off movement, hedge fund backed |
| [[Qwen]] | 2.5 | [[Alibaba]], largest training data (50T tokens) |
| [[Kimi]] | k2 | [[Moonshot AI]], strong creative writing |
| [[MiniMax]] | Various | Filed IPO |
| [[Zhipu]] | GLM-4 | Filed IPO, strong reasoning |

## Why they release open weights

US enterprises won't pay for API subscriptions to Chinese companies (security concerns). Open weights let them influence the growing AI market indirectly — developers use models without sending data to China.

Government sees open models building international influence. Incentives to keep it going.

## License advantage

Chinese open models use unrestricted licenses — no strings attached. [[Llama]] and [[Gemma]] have user limits and reporting requirements. This matters for production use.

## DeepSeek losing its crown

DeepSeek kicked off the movement but others catching up:
- Using DeepSeek's published architectures (same MoE design)
- More recent models often slightly better (leapfrogging)
- Kimi, Zhipu, MiniMax all showing strong results

DeepSeek secretive in communication but open in technical reports. Others like MiniMax and Moonshot actively seeking Western mindshare (IPO paperwork).

## US response

Gap motivated [[ATOM Project]] and renewed US focus on open models. July 2025: China released 4-5 DeepSeek-caliber models, US released zero.

## Business model uncertainty

No clear business model — same as US open models. Consolidation expected eventually but not in 2026. More open model builders coming than 2025.

## Related

- [[ATOM Project]] — US response
- [[DeepSeek]] — started the movement
- [[Export controls]] — constraints on Chinese compute
- [[Llama]] — US open model struggling to compete

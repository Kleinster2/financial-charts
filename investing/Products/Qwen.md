---
aliases:
  - Qwen
  - Qwen 2.5
  - Qwen 3
  - Qwen2.5-Max
  - Tongyi Qianwen
  - 通义千问
tags:
  - product-family
  - ai
  - open-source
  - china
parent_actor: "[[Alibaba]]"
parent_concept: "[[Frontier models]]"
---

# Qwen

[[Alibaba]]'s open-source LLM family. Qwen 3 (Apr 2025) trained on 36T tokens, supports 119 languages. Competitive with GPT-4 while free for commercial use (<$1M revenue).

## Quick stats

| Metric | Value |
|--------|-------|
| Current version | Qwen 3 (Apr 2025) |
| Training data | 36 trillion tokens |
| Languages | 119 |
| License | Apache 2.0 (open) |
| Parameters | 0.6B to 235B |
| Key strength | Open weights, multilingual |

---

## Version history

| Model | Release | Key changes |
|-------|---------|-------------|
| Qwen 1.0 | Aug 2023 | Initial release |
| Qwen 1.5 | Feb 2024 | Improved reasoning |
| **Qwen 2** | Jun 2024 | Major upgrade |
| **Qwen 2.5** | Sep 2024 | 29+ languages, 8K output |
| Qwen 2.5-Max | Jan 2025 | MoE, rivals DeepSeek-V3 |
| Qwen 2.5-VL | Jan 2025 | Vision-language |
| Qwen 2.5-Omni | Mar 2025 | Text/image/video/audio I/O |
| **Qwen 3** | Apr 2025 | 36T tokens, 119 languages, reasoning |

---

## Qwen 3 model sizes

| Model | Params | Architecture |
|-------|--------|--------------|
| Qwen3-0.6B | 0.6B | Dense |
| Qwen3-1.7B | 1.7B | Dense |
| Qwen3-4B | 4B | Dense |
| Qwen3-8B | 8B | Dense |
| Qwen3-14B | 14B | Dense |
| Qwen3-32B | 32B | Dense |
| Qwen3-30B-A3B | 30B (3B active) | MoE |
| Qwen3-235B-A22B | 235B (22B active) | MoE |

---

## Key capabilities

| Feature | Details |
|---------|---------|
| Reasoning | Toggle on/off (like o1, QwQ) |
| Coding | Rivals GPT-4 (Python, JS, C++) |
| Function calling | OpenAI-compatible format |
| Long output | Up to 8K tokens |
| Multimodal | Vision, audio (Omni variant) |

---

## Qwen 2.5-Max

| Aspect | Details |
|--------|---------|
| Architecture | Mixture-of-Experts |
| Training | 20 trillion tokens |
| Claims | Outperforms GPT-4o, DeepSeek-V3, Llama-405B |
| License | **Closed** (unlike other Qwen models) |

---

## Competitive position

| vs | Qwen advantage | Qwen weakness |
|----|---------------|---------------|
| [[GPT]] | Free, open weights | Ecosystem maturity |
| [[Llama]] | Multilingual (119 vs 8) | Meta's resources |
| [[DeepSeek-V]] | Alibaba backing | DeepSeek efficiency |

Most capable open-source model from China.

---

## Related

- [[Alibaba]] — parent actor
- [[DeepSeek-V]] — competitor
- [[Llama]] — competitor (open)
- [[GLM]] — competitor (China)
- [[Frontier models]] — category
- [[China]] — market

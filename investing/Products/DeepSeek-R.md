---
aliases:
  - DeepSeek-R
  - DeepSeek-R1
  - DeepSeek R1
  - R1
tags:
  - product
  - ai
  - china
parent_actor: "[[DeepSeek]]"
parent_concept: "[[Reasoning models]]"
---

# DeepSeek-R

[[DeepSeek]]'s reasoning model family. Chain-of-thought architecture. R1 triggered [[DeepSeek day]] — $600B wiped from [[NVIDIA]], largest single-day loss in US history.

## Quick stats (R1)

| Metric | Value |
|--------|-------|
| Type | Reasoning model (like [[ChatGPT]] o1) |
| Architecture | MoE with chain-of-thought |
| Efficiency | Lower cost/token than GPT-4 |
| Weights | Open (downloadable) |
| Inference | Runs on consumer hardware |
| Release | January 2025 |

---

## Version history

| Version | Release | Key changes |
|---------|---------|-------------|
| **DeepSeek-R1** | Jan 2025 | Reasoning model, open weights |
| R1 distilled (1.5B) | Jan 2025 | Smallest distilled version |
| R1 distilled (7B) | Jan 2025 | Consumer-friendly |
| R1 distilled (70B) | Jan 2025 | Largest distilled |
| **DeepSeek-R2** | Feb 2026 (expected) | Next-gen reasoning |

---

## Why R1 hit harder than V3

| Factor | V3 (Dec 2024) | R1 (Jan 2025) |
|--------|---------------|---------------|
| Task type | General | Reasoning (hardest) |
| Open weights | Yes | Yes |
| Consumer hardware | No | Yes |
| Market reaction | Muted | **$600B NVIDIA crash** |

**Reasoning is the hardest task.** Proving efficiency works for reasoning meant it works everywhere.

---

## Market impact

| Event | Details |
|-------|---------|
| Date | January 27, 2025 |
| NVIDIA loss | **$600B** (single day) |
| Tech selloff | ~$1T total |
| Name | [[DeepSeek day]] |

Largest single-day market cap loss in US history.

---

## Distilled versions

| Model | Params | Use case |
|-------|--------|----------|
| R1-distill-1.5B | 1.5B | Edge, mobile |
| R1-distill-7B | 7B | Consumer GPU |
| R1-distill-14B | 14B | Prosumer |
| R1-distill-32B | 32B | Workstation |
| R1-distill-70B | 70B | Server |

Distillation enables R1 reasoning on consumer hardware.

---

## Availability

| Platform | Status |
|----------|--------|
| [[Microsoft]] Azure | ✓ |
| [[Hugging Face]] | ✓ (open weights) |
| Self-hosted | ✓ |
| [[Alibaba]] Cloud | ✓ |

Azure listing notable — Microsoft offering Chinese model alongside [[ChatGPT]], [[Claude]].

---

## Regional adoption

[[Microsoft]] noted DeepSeek usage in Africa is **2-4x higher** than other regions. Cost efficiency driving adoption in price-sensitive markets.

---

## Related

- [[DeepSeek]] — parent actor
- [[DeepSeek-V]] — general model family
- [[DeepSeek day]] — market crash event
- [[Reasoning models]] — category
- [[Chinese open models]] — category
- [[Export controls]] — context

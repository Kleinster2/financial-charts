---
aliases: [Together, TogetherAI]
---
#actor #ai #cloud #inference #private

**Together AI** — AI cloud platform for training and inference. Open-source model focus. Competing with hyperscalers on price/performance.

---

## Why Together AI matters

| Metric | Value |
|--------|-------|
| Valuation | ~$3B+ (2024) |
| Focus | AI training & inference cloud |
| Differentiation | Open-source models, cost efficiency |
| Customers | Startups, enterprises avoiding hyperscaler lock-in |

---

## Business model

| Service | Description |
|---------|-------------|
| Inference API | Run open-source models ([[Llama]], Mistral, etc.) |
| Training | Fine-tuning, custom model training |
| Platform | Together Inference Engine |
| Pricing | Cheaper than [[OpenAI]]/[[Anthropic]] APIs |

**Positioning:** The "open-source model cloud" — run [[Llama]], Mixtral, etc. without own infrastructure.

---

## Open-source focus

**Unlike [[OpenAI]]/[[Anthropic]]:**
- Hosts open-source models ([[Llama]], Mistral, Falcon)
- Customers own their model weights
- No vendor lock-in
- Transparent pricing

**[[Target]]:** Companies wanting open-source AI without infra burden.

---

## Competitive landscape

| Player | Positioning |
|--------|-------------|
| **Together AI** | Open-source model cloud |
| [[Groq]] | Speed-optimized inference |
| [[Nebius]] | European GPU cloud |
| [[CoreWeave]] | Raw GPU cloud |
| [[Lambda Labs]] | Developer GPU cloud |
| Replicate | Model hosting |
| Anyscale | Ray-based platform |

---

## Founding team

- Founded by AI researchers
- Focus on distributed training efficiency
- Published research on training optimization

---

## Investment case

**Bull:**
- Open-source AI wave growing
- Cheaper than proprietary APIs
- Enterprise adoption increasing
- Strong technical team
- Avoids hyperscaler margins

**Bear:**
- Competing with well-funded players
- Hyperscalers can undercut on price
- Open-source models commoditizing
- Margin pressure

---

## Cap table / Investors

| Round | Date | Amount | Valuation |
|-------|------|--------|-----------|
| Seed | 2022 | $20M | — |
| Series A | 2023 | $102M | ~$700M |
| Series A-1 | 2024 | $106M | ~$1.25B |
| Series B | 2024 | — | ~$3B |

**Key investors:**

| Investor | Notes |
|----------|-------|
| [[NVIDIA]] | Strategic (GPU supply relationship) |
| [[Kleiner Perkins]] | Lead Series A |
| [[Salesforce]] Ventures | Enterprise AI focus |
| [[NEA]] | Growth investor |

**Total raised:** ~$250M+

**NVIDIA relationship:** Strategic investor — suggests GPU access/priority.

---

## Related

- [[Groq]] — inference competitor
- [[Nebius]] — GPU cloud competitor
- [[CoreWeave]], [[Lambda Labs]] — infrastructure peers
- [[Meta]] — [[Llama]] models hosted on Together
- [[Mistral]] — models hosted on Together


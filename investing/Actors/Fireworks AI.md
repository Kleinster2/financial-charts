---
aliases: []
---
#actor #ai #inference #usa #private

**Fireworks AI** — AI inference cloud built by the PyTorch team. 10T+ tokens/day, 10,000+ customers, $280M ARR. Fastest-growing inference infrastructure company. $4B valuation (Oct 2025).

---

## Why Fireworks matters

**The PyTorch pedigree matters.** Founded by [[Meta]]'s PyTorch team — the people who built the framework most AI models train on. They understand GPU optimization at the kernel level, which translates to inference speed and cost advantages.

| Metric | Value |
|--------|-------|
| Valuation | **$4B** (Oct 2025) |
| ARR | **$280M** (Oct 2025) |
| YoY growth | **~20x** ($6.5M → $280M in 12 months) |
| Total raised | **$327M** |
| Founded | 2022 |
| HQ | — |
| CEO | Lin Qiao (ex-[[Meta]]/PyTorch) |
| Tokens/day | **10T+** |
| Customers | **10,000+** |
| Profitability | Reportedly profitable |

---

## What Fireworks does

**Serverless inference cloud:**
- Custom CUDA kernels for optimized model serving
- Advanced model sharding + semantic caching
- 8 cloud providers, 18 global regions
- GPU complexity abstracted away
- 12x faster than vLLM, 40x faster than GPT-4 benchmarks

**Key differentiator:** Platform-agnostic serverless approach — developers deploy models without managing GPU infrastructure. Compound AI systems (multi-model pipelines) are first-class.

---

## Key customers

| Customer | Use case |
|----------|----------|
| [[Uber]] | Production AI applications |
| [[Shopify]] | AI-powered commerce |
| [[Cursor]] | Code generation inference |
| [[DoorDash]] | AI features |
| [[GitLab]] | AI dev tools |
| Genspark | AI search |
| Retell AI | Voice AI |

10x customer growth from Series B to Series C. 23,000+ developers by end of 2024.

---

## Founders

| Person | Role | Background |
|--------|------|------------|
| **Lin Qiao** | CEO | [[IBM]] → LinkedIn → [[Meta]] (PyTorch team) |
| Dmytro Dzhulgakov | Co-founder | [[Meta]]/PyTorch (Ukrainian) |
| Dmytro Ivchenko | Co-founder | [[Meta]]/PyTorch (Ukrainian) |

The team experienced the CPU→GPU shift firsthand at [[Meta]], then built Fireworks to solve inference at scale.

---

## Funding history

| Round | Date | Amount | Valuation | Lead |
|-------|------|--------|-----------|------|
| Series C | **Oct 2025** | **$250M** | **$4B** | Lightspeed, Index, Evantic |
| Series B | Jul 2024 | $52M | ~$552M | Sequoia |
| Series A | — | ~$25M | — | [[Benchmark]] |
| **Total** | | **$327M** | | |

**Key investors:**

| Investor | Notes |
|----------|-------|
| [[Sequoia Capital]] | Series B lead, continued in C |
| [[Lightspeed Venture Partners]] | Series C co-lead |
| [[Index Ventures]] | Series C co-lead |
| Evantic | Series C co-lead |
| [[Benchmark]] | Early investor |
| [[NVIDIA]] | Series B participant |
| [[AMD]] | Series B participant |
| [[Databricks Ventures]] | Series B participant |
| [[MongoDB]] Ventures | Series B participant |

Both NVIDIA and AMD investing in the same inference startup — rare alignment.

---

## Growth trajectory

| Period | ARR | Customers | Tokens/day |
|--------|-----|-----------|------------|
| May 2024 | ~$6.5M | ~1,000 | — |
| Feb 2024 | — | — (12K devs) | — |
| Dec 2024 | — | — (23K devs) | — |
| Oct 2025 | **$280M** | **10,000+** | **10T+** |

**20x ARR growth in 12 months** — among the fastest revenue ramps in enterprise software history.

**Plans:** 3-4x compute footprint expansion, 150+ new hires (AI researchers, engineers, sales).

---

## Competitive landscape

| Company | Valuation | Approach | Revenue |
|---------|-----------|----------|---------|
| **Fireworks AI** | **$4B** | Serverless inference cloud | $280M ARR |
| [[Baseten]] | $5B (Jan 2026) | Model deployment platform | — |
| [[Together AI]] | ~$3B | Training + inference | — |
| [[Cerebras]] | $22B (Jan 2026) | Custom inference chips | $136M (2023) |
| [[Groq]] | NVIDIA-partnered | LPU inference chips | — |

**Positioning:** Fireworks competes on software optimization (CUDA kernels, serverless) rather than custom silicon. GPU-native approach vs Cerebras/Groq hardware approach.

---

## Investment case

**Bull:**
- 20x revenue growth, reportedly profitable — rare combination
- PyTorch founders = deep GPU expertise
- Both NVIDIA and AMD invested — hardware-agnostic positioning
- 10T tokens/day proves production scale
- Inference TAM growing faster than training
- Enterprise customers ([[Uber]], [[Shopify]]) = sticky revenue

**Bear:**
- Hyperscaler inference offerings (AWS Bedrock, Azure AI, GCP [[Vertex]]) competing
- Custom silicon (Cerebras, Groq) could undercut GPU-based inference on cost
- Developer-facing → vulnerable to platform shifts
- $4B valuation requires sustained hypergrowth
- [[Cursor]] also uses [[Baseten]] — customers multi-source inference

---

## Quick stats

| Metric | Value |
|--------|-------|
| Ticker | Private |
| Valuation | **$4B** (Oct 2025) |
| ARR | $280M |
| Total raised | $327M |
| Founded | 2022 |
| CEO | Lin Qiao |
| Key backers | Sequoia, Lightspeed, NVIDIA, AMD |

*Updated 2026-01-23*

---

## Related

- [[NVIDIA]] — investor (Series B), GPU supplier
- [[AMD]] — investor (Series B), GPU supplier
- [[Baseten]] — inference competitor/peer ($5B, Jan 2026)
- [[Cerebras]] — inference competitor (custom chips)
- [[Groq]] — inference competitor (NVIDIA-partnered)
- [[Inference disaggregation]] — market context
- [[Training-inference convergence]] — architectural trend

*Sources: BusinessWire Oct 2025, WSJ Jan 2026, Sacra*

---
aliases: [Magic]
---
#actor #ai #coding #usa #private

**Magic AI** — 100M token context window. Eric Schmidt backed. 8,000 H100s. AGI ambitions via code.

---

## Why Magic AI matters

Betting on ultra-long context as the unlock:

| Metric | Value |
|--------|-------|
| Context window | 100M tokens |
| Total raised | $515M |
| Compute | 8,000 H100s |
| Thesis | AGI through code automation |

---

## Long context innovation

**LTM (Long-term Memory Network):**

| Metric | Value |
|--------|-------|
| Context | 100M tokens |
| Equivalent | 10M lines of code |
| Equivalent | 750 novels |
| Efficiency | 1,000x faster decoding |

**Why it matters:** Can understand entire codebases, not just snippets.

---

## Funding

**$515M total:**

| Round | Amount | Key investors |
|-------|--------|---------------|
| Earlier | $145M | Nat Friedman, Daniel Gross |
| Aug 2024 | $320M | Eric Schmidt, CapitalG, Sequoia, Atlassian |

**Investors:**
- Eric Schmidt (ex-Google CEO)
- [[Sequoia Capital]]
- CapitalG (Alphabet)
- Jane Street
- Atlassian
- Nat Friedman (ex-GitHub CEO)
- Daniel Gross
- Elad Gil

---

## Compute infrastructure

**Massive GPU allocation:**
- 8,000 H100s currently
- Google Cloud partnership
- Magic-G4: H100 supercomputer
- Magic-G5: Blackwell B200 (tens of thousands)

Building frontier-scale training capability.

---

## Founding team

**Founded 2022:**
- Sebastian De Ro (CEO)
- Eric Steinberger

Building models in-house, not just using APIs.

---

## AGI thesis

**Code as path to AGI:**
> "The most promising path to safe AGI is to automate AI research and code generation to improve models and solve alignment."

**Approach:**
- Frontier-scale pre-training
- Domain-specific RL
- Ultra-long context
- Inference-time compute

More ambitious than Cursor/Cognition — building foundation models.

---

## Competitive position

| Company | Approach | Magic vs |
|---------|----------|----------|
| [[Anysphere]] | IDE + API calls | Magic builds own models |
| [[Cognition]] | Agent + IDE | Magic = longer context |
| [[Anthropic]]/[[OpenAI]] | General LLMs | Magic = code-specialized |

Magic = most vertically integrated of AI coding startups.

---

## Semiconductor relevance

**Direct compute buyer:**
- 8,000 H100s (current)
- Tens of thousands B200s (coming)
- Google Cloud partnership
- Significant NVIDIA customer

---

## Investment case

**Bull:**
- 100M context = differentiated
- Own models = not API-dependent
- Eric Schmidt backing
- Massive compute investment
- AGI optionality

**Bear:**
- No product shipping at scale yet
- Raised millions without product
- Cursor/Cognition have revenue
- Frontier model training expensive
- Anthropic/OpenAI could match context

---

## Quick stats

| Metric | Value |
|--------|-------|
| Ticker | Private |
| Valuation | ~$1.5B |
| Total raised | $515M |
| Context | 100M tokens |
| Compute | 8,000+ H100s |

*Updated 2026-01-01*

---

Related: [[Anysphere]], [[Cognition]], [[Sequoia Capital]], [[NVIDIA]], [[Anthropic]], [[OpenAI]]

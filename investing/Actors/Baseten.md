---
aliases: []
---
#actor #ai #inference #usa #private

**Baseten** — AI inference infrastructure startup. Helps companies deploy and run large AI models at scale. Aims to be the "AWS for inference." $5B valuation (Jan 2026).

---

## Why Baseten matters

**Inference infrastructure is the next battleground.** As AI shifts from training to deployment, companies need specialized platforms to serve models cost-effectively at scale. Baseten is positioning as the infrastructure layer between model providers and applications.

| Metric | Value |
|--------|-------|
| Valuation | **$5B** (Jan 2026) |
| Previous valuation | ~$2B (implied from raise history) |
| Total raised | **$585M** |
| Founded | 2019 |
| HQ | San Francisco |
| CEO | Tuhin Srivastava |
| Positioning | "AWS for inference" |

---

## What Baseten does

**Model deployment platform:**
- Deploys and serves large AI models in production
- GPU infrastructure management
- Auto-scaling for inference workloads
- Optimized model serving (latency, throughput, cost)

**Key customers:**
- [[Cursor]] — AI code editor (inference for code generation)
- [[Notion]] — AI-powered workspace features

---

## Funding history

| Round | Date | Amount | Valuation | Lead |
|-------|------|--------|-----------|------|
| Latest | **Jan 2026** | **$300M** | **$5B** | [[IVP]], [[CapitalG]] |
| Prior rounds | 2024-2025 | ~$285M | — | Various |
| **Total** | | **$585M** | | |

Third funding round in 12 months — accelerating capital deployment.

**Key investors:**

| Investor | Notes |
|----------|-------|
| **[[NVIDIA]]** | **$150M** in Jan 2026 round (customer's chips) |
| [[IVP]] | Co-led Jan 2026 |
| [[CapitalG]] | Co-led Jan 2026 (Alphabet's growth fund) |
| Bond | Existing investor |
| Greylock | Existing investor |
| [[Spark Capital]] | Existing investor |

---

## NVIDIA investment significance

NVIDIA's $150M investment (half the round) fits a pattern of investing in customers to drive GPU demand:

| NVIDIA investment | Amount | Pattern |
|-------------------|--------|---------|
| **Baseten** | **$150M** | Inference infrastructure |
| [[OpenAI]] | Up to $100B commitment | Model training/inference |
| [[CoreWeave]] | Investor + priority allocation | GPU cloud |
| [[Groq]] | $20B licensing deal | Inference architecture |

**The flywheel:** NVIDIA funds inference startups → they buy more GPUs → inference demand grows → validates NVIDIA's inference roadmap (Vera Rubin, Rubin SRAM).

---

## Competitive landscape (inference infrastructure)

| Company | Valuation | Approach |
|---------|-----------|----------|
| **Baseten** | **$5B** | Model deployment platform |
| [[Fireworks AI]] | $4B (Oct 2025) | Serverless inference cloud (PyTorch team) |
| [[Cerebras]] | $22B (Jan 2026 talks) | Custom inference chips + cloud |
| [[Groq]] | NVIDIA-partnered | LPU inference chips |
| [[Together AI]] | ~$3B | Training + inference platform |
| Anyscale/Ray | — | Distributed compute |

**Differentiation:** Baseten focuses on the deployment/orchestration layer rather than custom silicon. Platform-agnostic approach works with NVIDIA GPUs.

---

## Investment case

**Bull:**
- Inference compute growing faster than training
- NVIDIA backing validates demand thesis
- Strong customer base (Cursor, Notion — fast-growing AI apps)
- "AWS for inference" TAM is massive
- Three rounds in one year signals strong revenue growth

**Bear:**
- Hyperscalers (AWS, GCP, Azure) offer competing inference services
- Thin margins in infrastructure
- Customer concentration risk
- $5B valuation requires significant revenue scale
- Custom silicon (Groq, Cerebras) could disintermediate GPU-based platforms

---

## Quick stats

| Metric | Value |
|--------|-------|
| Ticker | Private |
| Valuation | **$5B** (Jan 2026) |
| Total raised | $585M |
| Founded | 2019 |
| CEO | Tuhin Srivastava |
| Key backer | NVIDIA ($150M) |

*Updated 2026-01-23*

---

## Related

- [[NVIDIA]] — investor ($150M, Jan 2026), GPU supplier
- [[NVIDIA as kingmaker]] — investment pattern (funding customers)
- [[Cerebras]] — inference competitor (custom chips)
- [[Groq]] — inference competitor (NVIDIA-partnered)
- [[Notion]] — customer
- [[Inference disaggregation]] — market context
- [[Fireworks AI]] — inference peer ($4B, PyTorch team)
- [[Training-inference convergence]] — architectural trend

*Source: WSJ, Jan 20 2026*

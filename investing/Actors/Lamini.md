# Lamini

#actor #startup #usa #ai #private #enterprise

**Lamini** — Enterprise LLM fine-tuning platform. Founded by Sharon Zhou ([[Andrew Ng]]'s PhD student) and Greg Diamos (MLPerf co-founder). **$25M Series A (May 2024).** Investors: [[Andrew Ng]], [[Andrej Karpathy]], Amplify, First Round. Alternative to OpenAI/Anthropic API dependency.

---

## Key facts

| Metric | Value |
|--------|-------|
| Founded | 2022 |
| HQ | Palo Alto, CA |
| Raised | $25M Series A |
| Stage | Series A |
| Focus | Enterprise LLM fine-tuning |

---

## Founders

| Person | Role | Background |
|--------|------|------------|
| **[[Sharon Zhou]]** | CEO | [[Stanford]] PhD under [[Andrew Ng]], MIT 35 Under 35 |
| **[[Greg Diamos]]** | CTO | Co-founded MLPerf, ex-[[Baidu]] AI, [[NVIDIA]] CUDA |

**[[Andrew Ng]] connection:** Sharon Zhou was Ng's PhD student. He's both advisor and investor. They co-created the "Finetuning Large Language Models" course together.

---

## Cap table

### Funding

| Round | Date | Amount | Lead |
|-------|------|--------|------|
| Seed | 2023 | — | [[First Round Capital]] |
| Series A | May 2024 | $25M | Amplify Partners |
| **Total** | | **$25M+** | |

### Key investors

| Investor | Notes |
|----------|-------|
| Amplify Partners | Series A lead |
| [[First Round Capital]] | Seed lead, Series A |
| **[[Andrew Ng]]** | Advisor, investor |
| **[[Andrej Karpathy]]** | Angel |
| Drew Houston | [[Dropbox]] CEO |
| Dylan Field | [[Figma]] CEO |

---

## Product

### What Lamini does

Enterprise platform for fine-tuning LLMs on proprietary data:

| Feature | Benefit |
|---------|---------|
| **Fine-tuning** | Customize models for specific tasks |
| **Memory RAG** | 90-95% accuracy vs 50% baseline |
| **On-prem option** | Air-gapped deployment for security |
| **Multi-GPU** | [[AMD]] or [[NVIDIA]] support |
| **Meta partnership** | Official [[Llama]] 3 fine-tuning recipes |

### Why it matters

**Enterprise AI independence:** Companies can fine-tune open models ([[Llama]]) instead of depending on OpenAI/Anthropic APIs.

| Approach | [[Trade]]-off |
|----------|-----------|
| OpenAI API | Easy but dependent, data leaves company |
| Lamini fine-tuning | More work but owned, data stays internal |

---

## Differentiation

### vs OpenAI/Anthropic

| Dimension | Lamini | OpenAI/Anthropic |
|-----------|--------|------------------|
| Data privacy | On-prem option | Cloud only |
| Model ownership | You own fine-tuned model | Renting API |
| Customization | Deep fine-tuning | Prompting, light fine-tuning |
| Cost at scale | Lower (own infra) | Higher (per-token) |

### vs Competitors

| Competitor | Lamini difference |
|------------|-------------------|
| [[Together AI]] | More enterprise focus |
| Anyscale | More fine-tuning specific |
| Weights & Biases | W&B is MLOps, Lamini is fine-tuning |

---

## [[Andrew Ng]] ecosystem

Lamini is part of [[Andrew Ng]]'s AI education + startup network:

| Entity | Connection |
|--------|------------|
| DeepLearning.AI | Sharon Zhou course instructor |
| Coursera | Ng co-founded |
| Landing AI | Ng's AI company |
| AI Fund | Ng's venture fund |

---

## Investment relevance

**Why track Lamini:**

1. **Enterprise AI independence** — Alternative to API dependency
2. **[[Andrew Ng]] signal** — His network bets on this
3. **Open model ecosystem** — [[Llama]] fine-tuning play
4. **Early stage** — $25M, could grow significantly

**Risks:**
- Small scale vs well-funded competitors
- Fine-tuning may commoditize
- Enterprises may default to OpenAI anyway

---

## Related

- [[Andrej Karpathy]] — angel investor
- [[Andrew Ng]] — co-founder's advisor, investor
- [[Meta]] — [[Llama]] partnership
- [[Anthropic]], [[OpenAI]] — competitors (API model)

---

Sources:
- [SiliconANGLE - Series A](https://siliconangle.com/2024/05/03/lamini-raises-25m-ai-development-inference-platform/)
- [Lamini official site](https://www.lamini.ai/)
- [Tracxn - Lamini profile](https://tracxn.com/d/companies/lamini/)

*Created 2026-01-14*

#actor #ai #inference #nvidia

**Groq** — inference-focused chip company, acquired by [[NVIDIA]] for $20B (Dec 2025).

---

## What they built

**LPU (Language Processing Unit)** — inference-specific architecture:
- 10x faster inference than GPUs
- 1/10th energy consumption
- Optimized for transformer models

Not a GPU — purpose-built for inference workloads.

---

## The acquisition

**NVIDIA acquired Groq for $20B (Dec 2025)** — largest NVIDIA deal ever.

Why it matters:
- NVIDIA entering non-GPU inference market
- Defensive move against inference commoditization
- Owns potential competitor before it scales

See [[Inference economics]] — inference margins collapsing, NVIDIA needed a play.

---

## Strategic significance

**For NVIDIA:**
- Diversifies beyond CUDA/GPU architecture
- Captures inference layer before commoditization
- Blocks competitors from Groq partnership

**For inference market:**
- Validates that GPUs aren't optimal for inference
- Specialized silicon has a future
- But now under NVIDIA umbrella

---

## For theses

- [[NVIDIA]] — moat expansion via acquisition
- [[Inference economics]] — validates inference specialization
- [[Short TSMC long Korea]] — NVIDIA exploring Samsung post-Groq

---

Related: [[NVIDIA]], [[Inference economics]], [[AI Race]], [[CUDA moat]]
